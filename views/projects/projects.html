<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Projects and Achievements</title>
    <link rel="stylesheet" href="/font.css" />
    <link rel="stylesheet" href="/styles.css" />
    <link rel="stylesheet" href="/views/projects/projects.css" />
    <link
      href="https://fonts.googleapis.com/css2?family=K2D:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800&display=swap"
      rel="stylesheet"
    />
    <script type="module">
      import { importHtml } from "/core/framework/index.js";
      import { elementProcessor } from "/core/framework/index.js";

      importHtml({
        path: "/components/navbar/navbar.html",
        elementId: "importedHeader",
        document: document,
      });

      importHtml({
        path: "/assets/svg/projects-bg/projects-bg.svg",
        elementId: "importedBg",
        document: document,
      });

      elementProcessor({
        document: document,
      }).shrinkElement({
        element: document.getElementById("importedBg"),
        height: document.body.clientHeight + 200,
      });
    </script>
  </head>
  <body>
    <div id="importedHeader"></div>
    <div id="importedBg"></div>
    <main class="projects-main">
      <h1 class="k2d-semibold">Projects and Achievements</h1>
      <div class="project">
        <h1 class="k2d-semibold">Project 1: Advanced Web Scraper</h1>
        <h2 class="k2d-semibold">Description:</h2>
        <p>
          The Advanced Web Scraper is a highly sophisticated tool designed to
          extract large volumes of data from various websites efficiently. This
          scraper is built to handle dynamic content, manage CAPTCHA challenges,
          and organize the scraped data into a structured format for analysis
          and use in different applications.
        </p>

        <img
          src="/assets/img/webscraper.png"
          alt="Web Scraper"
          class="diagram"
        />

        <h3 class="k2d-semibold">Key Features:</h3>
        <ul>
          <li>
            Capable of scraping data from both static and dynamic web pages.
          </li>
          <li>
            Utilizes headless browsers like Puppeteer to handle JavaScript-heavy
            sites.
          </li>
          <li>
            Integrates CAPTCHA-solving services to bypass anti-scraping
            measures.
          </li>
          <li>
            Stores data in a well-structured format, such as CSV or JSON, for
            easy analysis.
          </li>
          <li>
            Provides scheduling functionality to automate scraping tasks at
            regular intervals.
          </li>
        </ul>

        <h3 class="k2d-semibold">Technologies Used:</h3>
        <ul>
          <li>Programming Languages: Python, JavaScript</li>
          <li>Libraries and Tools: BeautifulSoup, Scrapy, Puppeteer</li>
          <li>Data Storage: MongoDB, MySQL</li>
          <li>Automation: Cron Jobs for task scheduling</li>
        </ul>

        <h3 class="k2d-semibold">Challenges and Solutions:</h3>
        <ul>
          <li>
            <strong>Challenge:</strong> Handling dynamic content generated by
            JavaScript.<br />
            <strong>Solution:</strong> Used Puppeteer to control a headless
            browser, allowing the scraper to wait for and interact with
            JavaScript-generated content.
          </li>
          <li>
            <strong>Challenge:</strong> Bypassing CAPTCHA challenges.<br />
            <strong>Solution:</strong> Integrated third-party CAPTCHA-solving
            services and implemented machine learning models to automatically
            solve CAPTCHA challenges.
          </li>
          <li>
            <strong>Challenge:</strong> Ensuring data consistency and avoiding
            IP bans.<br />
            <strong>Solution:</strong> Implemented proxy rotation and request
            throttling to mimic human browsing behavior and avoid detection.
          </li>
        </ul>
      </div>

      <h1 class="k2d-semibold">
        Project 2: Machine Learning Pipeline Refactoring
      </h1>
      <div class="project">
        <h2 class="k2d-semibold">Description:</h2>
        <p>
          This project involved refactoring a machine learning pipeline used for
          predictive analytics in a financial application. The goal was to
          improve code readability, performance, and maintainability, as well as
          to update documentation and fix existing shell scripts.
        </p>

        <img src="/assets/img/querymodel.jpg" alt="ML Pipeline" class="diagram" />

        <h3 class="k2d-semibold">Key Features:</h3>
        <ul>
          <li>
            Refactored the codebase for better modularity and readability.
          </li>
          <li>
            Improved the performance of data processing and model training
            stages.
          </li>
          <li>
            Updated and expanded documentation for better clarity and ease of
            use.
          </li>
          <li>Fixed and optimized shell scripts used for automation tasks.</li>
        </ul>

        <h3 class="k2d-semibold">Technologies Used:</h3>
        <ul>
          <li>Programming Languages: Python, Shell Scripting</li>
          <li>Machine Learning: scikit-learn, pandas</li>
          <li>Documentation: Sphinx, Markdown</li>
          <li>Version Control: Git</li>
        </ul>

        <h3 class="k2d-semibold">Challenges and Solutions:</h3>
        <ul>
          <li>
            <strong>Challenge:</strong> Ensuring backward compatibility while
            refactoring.<br />
            <strong>Solution:</strong> Wrote extensive tests and used version
            control to manage changes, ensuring that the refactored code
            produced the same results as the original.
          </li>
          <li>
            <strong>Challenge:</strong> Improving performance without
            sacrificing accuracy.<br />
            <strong>Solution:</strong> Profiled the code to identify bottlenecks
            and implemented efficient algorithms and data structures to enhance
            performance.
          </li>
        </ul>
      </div>
    </main>
  </body>
</html>
